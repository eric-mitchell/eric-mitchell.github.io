<!doctype html><html lang=en-us><head><meta name=generator content="Hugo 0.105.0"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><script src=https://code.jquery.com/jquery-3.5.1.slim.min.js integrity="sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=" crossorigin=anonymous></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css integrity=sha384-TX8t27EcRE3e/ihU7zmQxVncDAy5uIKz4rEkgIXeMed4M0jlfIDPvg6uqKI2xXr2 crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Nanum+Myeongjo&family=Noto+Serif+JP&family=Cormorant+Garamond&family=Libre+Baskerville&family=Source+Serif+Pro&family=Crimson+Text&family=Inter&family=Crimson+Pro&family=Literata&family=Ubuntu+Mono&family=Inter&family=Roboto"><link rel=stylesheet type=text/css href=/css/style.css><title>Eric A Mitchell</title></head><body class="container d-flex flex-column min-vh-100"><div class="row w-100"><div class="col w-100"><div class="about row w-100"><div class="row w-100 justify-content-center"><img class=rounded-circle src=images/profile.png alt=profile_picture id=profile_picture></div><div class="row w-100 justify-content-center main_color" id=full_name>Eric Anthony Mitchell</div><div class="affiliations row w-100 justify-content-center"><div class="row w-100 justify-content-center"><div class="row w-100 justify-content-center" id=title-name><span class=main_color id=title>Ph.D. Student,</span>
<span id=name class=text-muted>Stanford University</span></div><div class="row w-100 justify-content-center text-muted" id=email>eric.mitchell@cs.stanford.edu</div></div></div><div class="socials row w-100 justify-content-center"><div class="row w-100 justify-content-center"><a class=main_color rel=me href='https://scholar.google.com/citations?user=q77J4fgAAAAJ&hl=en' target=_blank><i class="ai ai-2x ai-google-scholar academic_icons_customize"></i></a>
<a class=main_color rel=me href=https://github.com/eric-mitchell target=_blank><i data-feather=github></i></a>
<a class=main_color rel=me href=https://twitter.com/_eric_mitchell_ target=_blank><i data-feather=twitter></i></a>
<a class=main_color rel=me href=https://linkedin.com/in/ericanthonymitchell target=_blank><i data-feather=linkedin></i></a></div></div><div class="introduction row w-100"><div class="col w-100"><p>I am a fourth-year PhD student in Stanford&rsquo;s CS department, where I&rsquo;m fortunate to be advised by <a href=https://ai.stanford.edu/~cbfinn/>Chelsea Finn</a> and <a href=https://nlp.stanford.edu/manning/>Christopher D. Manning</a>. The goal of my research is to make the knowledge embedded in neural networks more reusable and updatable in an ever-changing world. I&rsquo;m interested in deep learning generally, as well as meta-learning and continual learning more specifically, particularly in the context large language models (or &lsquo;Foundation Models&rsquo;). Much of my PhD has been generously supported by a <a href=https://knight-hennessy.stanford.edu>Knight-Hennessy Graduate Fellowship</a>.</p><p>You can find my CV <a href=cv.pdf>here</a>.</p><p>In the summer of 2022, I was a research scientist intern at DeepMind in London, where I was lucky to spend four months working with <a href=https://sites.google.com/view/junyoung-ai/>Junyoung Chung</a>, <a href=http://www.kushman.org/>Nate Kushman</a>, and <a href=https://avdnoord.github.io/homepage/>AÃ¤ron van den Oord</a>.</p><p>Before my PhD, I was a research engineer at <a href=https://research.samsung.com/aicenter_ny>Samsung&rsquo;s AI Center</a> in New York City, where I learned constantly from <a href=https://www-users.cse.umn.edu/~isler/>Volkan Isler</a>, <a href=https://tech.cornell.edu/people/daniel-d-lee-2/>Daniel D. Lee</a>, and many other wonderful (and patient) people. As an undergraduate, I completed my thesis under the guidance of <a href=http://pni.princeton.edu/faculty/h.-sebastian-seung>H. Sebastian Seung</a> after many hours in the <a href=https://seunglab.org>Seung Lab</a> at the <a href=http://pni.princeton.edu>Princeton Neuroscience Institute</a>. I also competed for <a href=https://twitter.com/princetongolf>Princeton&rsquo;s varsity men&rsquo;s golf team</a>.</p><p>In my free time, I make music for guitar and voice. I enjoy the outdoors, particularly golf courses and mountains.</p></div></div></div><div class="about row w-100"></div></div></div><div class="row w-100"><div class="col w-100"><div class="row w-100"><div class="col w-100"><h3 class="row w-100 section-title main_color">Recent Papers</h3></div></div><div class="publications row w-100"><div class="col w-100"><div class="publication row w-100"><div class="section-1 w-100"><span class=publication-title>Enhancing Self-Consistency and Performance of Pretrained Language Models with NLI</span></div><div class="section-2 w-100"><span>Eric A Mitchell</span>
<span class=separator>,</span>
<span>Joseph J Noh</span>
<span class=separator>,</span>
<span>Siyan Li</span>
<span class=separator>,</span>
<span>William S Armstrong</span>
<span class=separator>,</span>
<span>Ananth Agarwal</span>
<span class=separator>,</span>
<span>Patrick Liu</span>
<span class=separator>,</span>
<span>Chelsea Finn</span>
<span class=separator>,</span>
<span>Christopher D Manning</span><br><span class="text-muted publication-name">EMNLP Oral (&lt;4% of submitted papers),</span>
<span class="text-muted publication-date">2022</span></div><div class="section-3 w-100"><a class="main_color rounded" href=https://ericmitchell.ai/concord.pdf target=_blank>pdf</a>
<a class="main_color rounded" href=https://ericmitchell.ai/emnlp-2022-concord/ target=_blank>site</a></div></div><div class="publication row w-100"><div class="section-1 w-100"><span class=publication-title>Memory-Based Model Editing at Scale</span></div><div class="section-2 w-100"><span>Eric A Mitchell</span>
<span class=separator>,</span>
<span>Charles Lin</span>
<span class=separator>,</span>
<span>Antoine Bosselut</span>
<span class=separator>,</span>
<span>Chelsea Finn</span>
<span class=separator>,</span>
<span>Christopher D Manning</span><br><span class="text-muted publication-name">ICML,</span>
<span class="text-muted publication-date">2022</span></div><div class="section-3 w-100"><a class="main_color rounded" href=https://arxiv.org/abs/2206.06520 target=_blank>pdf</a>
<a class="main_color rounded" href=https://sites.google.com/view/serac-editing target=_blank>site</a></div></div><div class="publication row w-100"><div class="section-1 w-100"><span class=publication-title>Self-Destructing Models: Increasing the Costs of Harmful Dual Uses in Foundation Models</span></div><div class="section-2 w-100"><span>Eric A Mitchell*</span>
<span class=separator>,</span>
<span>Peter Henderson*</span>
<span class=separator>,</span>
<span>Christopher D Manning</span>
<span class=separator>,</span>
<span>Dan Jurafsky</span>
<span class=separator>,</span>
<span>Chelsea Finn</span><br><span class="text-muted publication-name">ICML Workshop on Pre-training,</span>
<span class="text-muted publication-date">2022</span></div><div class="section-3 w-100"><a class="main_color rounded" href="https://openreview.net/pdf?id=fYPC0TnrItR" target=_blank>pdf</a></div></div><div class="publication row w-100"><div class="section-1 w-100"><span class=publication-title>Fast Model Editing at Scale</span></div><div class="section-2 w-100"><span>Eric A Mitchell</span>
<span class=separator>,</span>
<span>Charles Lin</span>
<span class=separator>,</span>
<span>Antoine Bosselut</span>
<span class=separator>,</span>
<span>Chelsea Finn</span>
<span class=separator>,</span>
<span>Christopher D Manning</span><br><span class="text-muted publication-name">ICLR,</span>
<span class="text-muted publication-date">2022</span></div><div class="section-3 w-100"><a class="main_color rounded" href=https://arxiv.org/abs/2110.11309 target=_blank>pdf</a>
<a class="main_color rounded" href=https://github.com/eric-mitchell/mend target=_blank>repo</a>
<a class="main_color rounded" href=https://sites.google.com/view/mend-editing target=_blank>site</a></div></div><div class="publication row w-100"><div class="section-1 w-100"><span class=publication-title>Learning Language-Conditioned Robot Behavior from Offline Data and Crowd-Sourced Annotation</span></div><div class="section-2 w-100"><span>Suraj Nair</span>
<span class=separator>,</span>
<span>Eric A Mitchell</span>
<span class=separator>,</span>
<span>Kevin Chen</span>
<span class=separator>,</span>
<span>Brian Ichter</span>
<span class=separator>,</span>
<span>Silvio Savarese</span>
<span class=separator>,</span>
<span>Chelsea Finn</span><br><span class="text-muted publication-name">CoRL,</span>
<span class="text-muted publication-date">2022</span></div><div class="section-3 w-100"><a class="main_color rounded" href=https://arxiv.org/abs/2109.01115 target=_blank>pdf</a>
<a class="main_color rounded" href=https://github.com/suraj-nair-1/lorl target=_blank>repo</a>
<a class="main_color rounded" href=https://sites.google.com/view/robotlorl target=_blank>site</a></div></div><div class="publication row w-100"><div class="section-1 w-100"><span class=publication-title>On the Opportunities and Risks of Foundation Models</span></div><div class="section-2 w-100"><span>Stanford Center for Research on Foundation Models</span><br><span class="text-muted publication-name">Whitepaper,</span>
<span class="text-muted publication-date">2021</span></div><div class="section-3 w-100"><a class="main_color rounded" href=https://arxiv.org/abs/2108.07258 target=_blank>pdf</a></div></div><div class="publication row w-100"><div class="section-1 w-100"><span class=publication-title>Petascale Neural Circuit Reconstruction: Automated Methods</span></div><div class="section-2 w-100"><span>Sven Dorkenwald et al.</span><br><span class="text-muted publication-name">Preprint,</span>
<span class="text-muted publication-date">2021</span></div><div class="section-3 w-100"><a class="main_color rounded" href=https://www.biorxiv.org/content/10.1101/2021.08.04.455162v1.full target=_blank>pdf</a></div></div><div class="publication row w-100"><div class="section-1 w-100"><span class=publication-title>Offline Meta-Reinforcement Learning with Advantage Weighting</span></div><div class="section-2 w-100"><span>Eric A Mitchell</span>
<span class=separator>,</span>
<span>Rafael Rafailov</span>
<span class=separator>,</span>
<span>Xue Bin Peng</span>
<span class=separator>,</span>
<span>Sergey Levine</span>
<span class=separator>,</span>
<span>Chelsea Finn</span><br><span class="text-muted publication-name">ICML,</span>
<span class="text-muted publication-date">2021</span></div><div class="section-3 w-100"><a class="main_color rounded" href=https://arxiv.org/abs/2008.06043 target=_blank>pdf</a>
<a class="main_color rounded" href=https://github.com/eric-mitchell/macaw target=_blank>repo</a>
<a class="main_color rounded" href=https://sites.google.com/view/macaw-metarl/home target=_blank>site</a>
<a class="main_color rounded" href="https://www.youtube.com/watch?v=MbrwK-7yZ3M" target=_blank>video</a></div></div><div class="publication row w-100"><div class="section-1 w-100"><span class=publication-title>Geodesic-HOF: 3D Reconstruction Without Cutting Corners</span></div><div class="section-2 w-100"><span>Ziyun Wang</span>
<span class=separator>,</span>
<span>Eric A Mitchell</span>
<span class=separator>,</span>
<span>Volkan Isler</span>
<span class=separator>,</span>
<span>Daniel D Lee</span><br><span class="text-muted publication-name">AAAI,</span>
<span class="text-muted publication-date">2021</span></div><div class="section-3 w-100"><a class="main_color rounded" href=https://arxiv.org/abs/2006.07981 target=_blank>pdf</a></div></div><div class="publication row w-100"><div class="section-1 w-100"><span class=publication-title>Higher Order Function Networks for View Planning and Multi-View Reconstruction</span></div><div class="section-2 w-100"><span>Selim Engin</span>
<span class=separator>,</span>
<span>Eric A Mitchell</span>
<span class=separator>,</span>
<span>Daewon Lee</span>
<span class=separator>,</span>
<span>Volkan Isler</span>
<span class=separator>,</span>
<span>Daniel D Lee</span><br><span class="text-muted publication-name">ICRA,</span>
<span class="text-muted publication-date">2020</span></div><div class="section-3 w-100"><a class="main_color rounded" href=https://arxiv.org/abs/1910.02066 target=_blank>pdf</a></div></div><div class="publication row w-100"><div class="section-1 w-100"><span class=publication-title>Higher-Order Function Networks for Learning Composable 3D Object Representations</span></div><div class="section-2 w-100"><span>Eric A Mitchell</span>
<span class=separator>,</span>
<span>Selim Engin</span>
<span class=separator>,</span>
<span>Volkan Isler</span>
<span class=separator>,</span>
<span>Daniel D Lee</span><br><span class="text-muted publication-name">ICLR,</span>
<span class="text-muted publication-date">2020</span></div><div class="section-3 w-100"><a class="main_color rounded" href=https://arxiv.org/abs/1907.10388 target=_blank>pdf</a></div></div></div></div></div></div><footer class="mt-auto d-flex justify-content-center text-muted small secondary_font"><span class=text-muted>Copyright (c) 2022, Eric Anthony Mitchell,
<a class=text-muted href=https://github.com/hadisinaee/avicenna target=_blank>created by Avicenna
(MIT)</a></span></footer><script src=https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.bundle.min.js integrity=sha384-ho+j7jyWK8fNQe+A12Hb8AhRq26LrZ/JpcUGGOn+Y7RsweNrtN/tE3MoK7ZeZDyx crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/feather-icons/4.28.0/feather.min.js></script>
<script>feather.replace()</script></body></html>