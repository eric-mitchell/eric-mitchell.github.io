<!doctype html><html lang=en-us><head><meta name=generator content="Hugo 0.121.2"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><script src=https://code.jquery.com/jquery-3.5.1.slim.min.js integrity="sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=" crossorigin=anonymous></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css integrity=sha384-TX8t27EcRE3e/ihU7zmQxVncDAy5uIKz4rEkgIXeMed4M0jlfIDPvg6uqKI2xXr2 crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Nanum+Myeongjo&family=Noto+Serif+JP&family=Cormorant+Garamond&family=Libre+Baskerville&family=Source+Serif+Pro&family=Crimson+Text&family=Inter&family=Crimson+Pro&family=Literata&family=Ubuntu+Mono&family=Inter&family=Roboto"><link rel=stylesheet type=text/css href=/css/style.css><title>Eric Mitchell</title></head><body class="container d-flex flex-column min-vh-100"><div class="row w-100"><div class="col w-100"><div class="about row w-100"><div class="row w-100 justify-content-center"><img class=rounded-circle src=images/profile.png alt=profile_picture id=profile_picture></div><div class="row w-100 justify-content-center main_color" id=full_name>Eric Anthony Mitchell</div><div class="affiliations row w-100 justify-content-center"><div class="row w-100 justify-content-center"><div class="row w-100 justify-content-center" id=title-name><span class=main_color id=title>Ph.D. Candidate,
</span><span id=name class=text-muted>Stanford University</span></div><div class="row w-100 justify-content-center text-muted" id=email>eric.mitchell@cs.stanford.edu</div></div></div><div class="socials row w-100 justify-content-center"><div class="row w-100 justify-content-center"><a class=main_color rel=me href='https://scholar.google.com/citations?user=q77J4fgAAAAJ&amp;hl=en' target=_blank><i class="ai ai-2x ai-google-scholar academic_icons_customize"></i>
</a><a class=main_color rel=me href=https://github.com/eric-mitchell target=_blank><i data-feather=github></i>
</a><a class=main_color rel=me href=https://twitter.com/ericmitchellai target=_blank><i data-feather=twitter></i>
</a><a class=main_color rel=me href=https://linkedin.com/in/ericanthonymitchell target=_blank><i data-feather=linkedin></i></a></div></div><div class="introduction row w-100"><div class="col w-100"><p><strong>Fall 2023 update: I am going on both the industry and academic job markets very shortly (early 2024). If you think my experience would be a good fit for your organization or institution, reach out!</strong></p><p>I am a final-year PhD student in Stanford&rsquo;s CS department, where I&rsquo;m fortunate to be advised by <a href=https://ai.stanford.edu/~cbfinn/>Chelsea Finn</a> and <a href=https://nlp.stanford.edu/manning/>Christopher D. Manning</a>. The goal of my research is to make foundation models, particularly language models, a safer and easier to use technology. Much of my PhD has been generously supported by a <a href=https://knight-hennessy.stanford.edu>Knight-Hennessy Graduate Fellowship</a> and a Stanford Accelerator for Learning grant for <a href=https://acceleratelearning.stanford.edu/story/generative-ai-seed-grants/>Generative AI for the Future of Learning</a>.</p><p>You can find my CV <a href=cv.pdf>here</a>.</p><p>In the summer of 2022, I was a research scientist intern at DeepMind in London, where I was lucky to spend four months working with <a href=https://sites.google.com/view/junyoung-ai/>Junyoung Chung</a>, <a href=http://www.kushman.org/>Nate Kushman</a>, and <a href=https://avdnoord.github.io/homepage/>AÃ¤ron van den Oord</a>.</p><p>Before my PhD, I was a research engineer at <a href=https://research.samsung.com/aicenter_ny>Samsung&rsquo;s AI Center</a> in New York City, where I learned constantly from <a href=https://www-users.cse.umn.edu/~isler/>Volkan Isler</a>, <a href=https://tech.cornell.edu/people/daniel-d-lee-2/>Daniel D. Lee</a>, and many other wonderful (and patient) people. As an undergraduate, I completed my thesis under the guidance of <a href=http://pni.princeton.edu/faculty/h.-sebastian-seung>H. Sebastian Seung</a> after many hours in the <a href=https://seunglab.org>Seung Lab</a> at the <a href=http://pni.princeton.edu>Princeton Neuroscience Institute</a>. I also competed for <a href=https://twitter.com/princetongolf>Princeton&rsquo;s varsity men&rsquo;s golf team</a>.</p><p>In my free time, I make music for guitar and voice. I enjoy the outdoors, particularly playing golf, exploring mountains, and SCUBA diving.</p></div></div></div><div class="about row w-100"></div></div></div><div class="row w-100"><div class="col w-100"><div class="row w-100"><div class="col w-100"><h3 class="row w-100 section-title main_color">Selected Works</h3></div></div><div class="publications row w-100"><div class="col-lg-6 publication"><div class="section-1 w-100"><span class=publication-title>Fine-tuning Language Models for Factuality</span></div><div class="section-2 w-100"><span class=text-muted>Katherine Tian*,
</span><span class=text-muted><span style=font-weight:700>Eric Mitchell*</span>,
</span><span class=text-muted>Huaxiu Yao,</span><br><span class=text-muted>Christopher D. Manning,
</span><span class=text-muted>Chelsea Finn</span><br><span class=publication-venue>ICLR,
</span><span class=publication-date>2024</span></div><div class="section-3 w-100"><a class="main_color rounded" href=https://arxiv.org/abs/2310.12962 target=_blank>paper</a></div></div><div class="col-lg-6 publication"><div class="section-1 w-100"><span class=publication-title>An Emulator for Fine-Tuning Large Language Models using Small Language Models</span></div><div class="section-2 w-100"><span class=text-muted><span style=font-weight:700>Eric Mitchell</span>,
</span><span class=text-muted>Rafael Rafailov,
</span><span class=text-muted>Archit Sharma,</span><br><span class=text-muted>Chelsea Finn,
</span><span class=text-muted>Christopher D. Manning</span><br><span class=publication-venue>ICLR,
</span><span class=publication-date>2024</span></div><div class="section-3 w-100"><a class="main_color rounded" href=https://arxiv.org/abs/2310.12962 target=_blank>paper</a></div></div><div class="col-lg-6 publication"><div class="section-1 w-100"><span class=publication-title>Meta-Learning Online Adaptation of Language Models</span></div><div class="section-2 w-100"><span class=text-muted>Nathan Hu*,
</span><span class=text-muted><span style=font-weight:700>Eric Mitchell*</span>,
</span><span class=text-muted>Christopher D. Manning,</span><br><span class=text-muted>Chelsea Finn</span><br><span class=publication-venue>EMNLP,
</span><span class=publication-date>2023</span></div><div class="section-3 w-100"><a class="main_color rounded" href=https://github.com/zixia314/CaMeLS/tree/main target=_blank>code</a>
<a class="main_color rounded" href=https://arxiv.org/abs/2305.15076 target=_blank>paper</a></div></div><div class="col-lg-6 publication"><div class="section-1 w-100"><span class=publication-title>Just Ask for Calibration: Strategies for Eliciting Calibrated Confidence Scores from Language Models Fine-Tuned with Human Feedback</span></div><div class="section-2 w-100"><span class=text-muted>Katherine Tian*,
</span><span class=text-muted><span style=font-weight:700>Eric Mitchell*</span>,
</span><span class=text-muted>Allan Zhou,</span><br><span class=text-muted>Archit Sharma,
</span><span class=text-muted>Rafael Rafailov,
</span><span class=text-muted>Huaxiu Yao,</span><br><span class=text-muted>Chelsea Finn,
</span><span class=text-muted>Christopher D. Manning</span><br><span class=publication-venue>EMNLP,
</span><span class=publication-date>2023</span></div><div class="section-3 w-100"><a class="main_color rounded" href=https://arxiv.org/abs/2305.14975 target=_blank>paper</a></div></div><div class="col-lg-6 publication"><div class="section-1 w-100"><span class=publication-title>Direct Preference Optimization: Your Language Model is Secretly a Reward Model</span></div><div class="section-2 w-100"><span class=text-muted>Rafael Rafailov*,
</span><span class=text-muted>Archit Sharma*,
</span><span class=text-muted><span style=font-weight:700>Eric Mitchell*</span>,</span><br><span class=text-muted>Stefano Ermon,
</span><span class=text-muted>Christopher D. Manning,
</span><span class=text-muted>Chelsea Finn</span><br><span class=publication-venue>NeurIPS (Oral),
</span><span class=publication-date>2023</span></div><div class="section-3 w-100"><a class="main_color rounded" href=https://github.com/eric-mitchell/direct-preference-optimization target=_blank>code</a>
<a class="main_color rounded" href=https://arxiv.org/abs/2305.18290 target=_blank>paper</a></div></div><div class="col-lg-6 publication"><div class="section-1 w-100"><span class=publication-title>DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature</span></div><div class="section-2 w-100"><span class=text-muted><span style=font-weight:700>Eric Mitchell</span>,
</span><span class=text-muted>Yoonho Lee,
</span><span class=text-muted>Sasha Khazatsky,</span><br><span class=text-muted>Christopher D. Manning,
</span><span class=text-muted>Chelsea Finn</span><br><span class=publication-venue>ICML (Oral),
</span><span class=publication-date>2023</span></div><div class="section-3 w-100"><a class="main_color rounded" href=https://github.com/eric-mitchell/detect-gpt target=_blank>code</a>
<a class="main_color rounded" href=https://arxiv.org/abs/2301.11305v1.pdf target=_blank>paper</a>
<a class="main_color rounded" href=https://ericmitchell.ai/detectgpt/ target=_blank>website</a></div></div><div class="col-lg-6 publication"><div class="section-1 w-100"><span class=publication-title>Enhancing Self-Consistency and Performance of Pretrained Language Models with NLI</span></div><div class="section-2 w-100"><span class=text-muted><span style=font-weight:700>Eric Mitchell</span>,
</span><span class=text-muted>Joseph J. Noh,
</span><span class=text-muted>Siyan Li,</span><br><span class=text-muted>William S. Armstrong,
</span><span class=text-muted>Ananth Agarwal,
</span><span class=text-muted>Patrick Liu,</span><br><span class=text-muted>Chelsea Finn,
</span><span class=text-muted>Christopher D. Manning</span><br><span class=publication-venue>EMNLP (Oral),
</span><span class=publication-date>2022</span></div><div class="section-3 w-100"><a class="main_color rounded" href=https://github.com/eric-mitchell/concord target=_blank>code</a>
<a class="main_color rounded" href=https://aclanthology.org/2022.emnlp-main.115.pdf target=_blank>paper</a>
<a class="main_color rounded" href=https://ericmitchell.ai/emnlp-2022-concord/ target=_blank>website</a></div></div><div class="col-lg-6 publication"><div class="section-1 w-100"><span class=publication-title>Self-Destructing Models: Increasing the Costs of Harmful Dual Uses in Foundation Models</span></div><div class="section-2 w-100"><span class=text-muted>Peter Henderson*,
</span><span class=text-muted><span style=font-weight:700>Eric Mitchell*</span>,
</span><span class=text-muted>Christopher D. Manning,</span><br><span class=text-muted>Dan Jurafsky,
</span><span class=text-muted>Chelsea Finn</span><br><span class=publication-venue>AAAI/ACM Conference on AI, Ethics, and Society,
</span><span class=publication-date>2022</span></div><div class="section-3 w-100"><a class="main_color rounded" href=https://github.com/Breakend/SelfDestructingModels target=_blank>code</a>
<a class="main_color rounded" href=https://dl.acm.org/doi/10.1145/3600211.3604690 target=_blank>paper</a></div></div><div class="col-lg-6 publication"><div class="section-1 w-100"><span class=publication-title>Fast Model Editing at Scale</span></div><div class="section-2 w-100"><span class=text-muted><span style=font-weight:700>Eric Mitchell</span>,
</span><span class=text-muted>Charles Lin,
</span><span class=text-muted>Antoine Bosselut,</span><br><span class=text-muted>Chelsea Finn,
</span><span class=text-muted>Christopher D. Manning</span><br><span class=publication-venue>ICLR,
</span><span class=publication-date>2022</span></div><div class="section-3 w-100"><a class="main_color rounded" href=https://github.com/eric-mitchell/mend target=_blank>code</a>
<a class="main_color rounded" href=https://arxiv.org/abs/2110.11309 target=_blank>paper</a>
<a class="main_color rounded" href=https://sites.google.com/view/mend-editing target=_blank>website</a></div></div><hr></div></div></div><footer class="mt-auto d-flex justify-content-center text-muted small secondary_font"><span class=text-muted>Copyright (c) 2024, Eric Anthony Mitchell,
<a class=text-muted href=https://github.com/hadisinaee/avicenna target=_blank>created by Avicenna
(MIT)</a></span></footer><script src=https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.bundle.min.js integrity=sha384-ho+j7jyWK8fNQe+A12Hb8AhRq26LrZ/JpcUGGOn+Y7RsweNrtN/tE3MoK7ZeZDyx crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/feather-icons/4.28.0/feather.min.js></script><script>feather.replace()</script></body></html>